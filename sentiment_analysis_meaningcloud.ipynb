{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeea82a-3e6b-4bb9-99cf-f2cf861882af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas  # noqa\n",
    "import requests\n",
    "import time\n",
    "\n",
    "class TwitterClient(object):\n",
    "    '''\n",
    "    Generic Twitter Class for sentiment analysis.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Class constructor or initialization method.\n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console\n",
    "        load_dotenv()\n",
    "        consumer_key = os.getenv('TWITTER_API_KEY')\n",
    "        consumer_secret = os.getenv('TWITTER_SECRET_KEY')\n",
    "        access_token = os.getenv('TWITTER_ACCESS_TOKEN')\n",
    "        access_token_secret = os.getenv('TWITTER_ACCESS_TOKEN_SECRET')\n",
    "        twitter_bearer_token = os.getenv('TWITTER_BEARER_TOKEN')\n",
    "  \n",
    "        # attempt authentication\n",
    "        try:\n",
    "            # This is for oAuth1 which wouldn't work with the endpoints I needed\n",
    "            # create OAuthHandler object\n",
    "            # self.auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            # # set access token and secret\n",
    "            # self.auth.set_access_token(access_token, access_token_secret)\n",
    "            # # create tweepy API object to fetch tweets\n",
    "            \n",
    "            #oAuth2 authentication\n",
    "            self.api = tweepy.Client(bearer_token=twitter_bearer_token)\n",
    "        except:\n",
    "            print(\"Error: Authentication Failed\")\n",
    "  \n",
    "    def clean_tweet(self, tweet):\n",
    "        '''\n",
    "        clean tweet text by removing links, special characters\n",
    "        using regex.\n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "  \n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        '''\n",
    "        Classify sentiment of passed tweet\n",
    "        '''\n",
    "        # Set base URL and API key for meaningcloud\n",
    "        sentiment_url = \"https://api.meaningcloud.com/sentiment-2.1\"\n",
    "        key = os.getenv('MEANINGCLOUD_KEY')\n",
    "        \n",
    "        # Set payload in dict variable for passing to meaningcloud API\n",
    "        payload={\n",
    "            'key': key,\n",
    "            'txt': self.clean_tweet(tweet),\n",
    "            'lang': 'en',\n",
    "        }\n",
    "\n",
    "        # Call meaningcloud APi to get sentiment of each tweet text\n",
    "        response = requests.post(sentiment_url, data=payload)\n",
    "        # Parse response as json\n",
    "        analysis = response.json()\n",
    "    \n",
    "        # Sleep for 2 second to respect API rate limits\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Print out status code of each API call\n",
    "        print('Status code:', response.status_code)\n",
    "        \n",
    "        # Return sentiment based on values returned\n",
    "        if analysis['score_tag'] in ['P+', 'P']:\n",
    "            return 'positive'\n",
    "        elif analysis['score_tag'] == 'NEU':\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "  \n",
    "    def get_tweets(self, query, count):\n",
    "        '''\n",
    "        Main function to fetch tweets and parse them.\n",
    "        '''\n",
    "        # Create empty list variable to store parsed tweets\n",
    "        tweets = []\n",
    "\n",
    "        try:\n",
    "            # call twitter api to fetch tweets\n",
    "            fetched_tweets = self.api.search_recent_tweets(query=query, tweet_fields=['text'], max_results=count)\n",
    "            \n",
    "            # Iterate over each tweet returned and call function to get sentiment\n",
    "            for tweet in fetched_tweets.data:\n",
    "                \n",
    "                # Create empty dictionary variable to store required params of a tweet\n",
    "                parsed_tweet = {}\n",
    "\n",
    "                # Save text of tweet to dict variable\n",
    "                parsed_tweet['text'] = tweet.text\n",
    "                # Save sentiment of tweet to dict variable\n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
    "                # Append parsed tweets to tweets variable\n",
    "                tweets.append(parsed_tweet)\n",
    "\n",
    "            # return parsed tweets\n",
    "            return tweets\n",
    "\n",
    "        except Exception as e:\n",
    "            # print error (if any)\n",
    "            print(\"Error : \" + str(e))\n",
    "  \n",
    "def main():\n",
    "    # Create object of TwitterClient Class\n",
    "    api = TwitterClient()\n",
    "    \n",
    "    # Set list variable to contain Twitter hashtags for the top 10 collections by trading volume\n",
    "    #tag_list = [\"#meebits\", \"#cryptopunks\", \"#terraforms\", \"#mayc\", \"#moonbirds\", \"#azuki\", \"#bayc\", \"#dreadfulz\", \"#clonex\", \"#beanz\"]\n",
    "    tag_list = [\"#terraforms\", \"#mayc\"]\n",
    "    \n",
    "    # Set dict variable to contain the results\n",
    "    results_dict = {\n",
    "        'tag' : tag_list,\n",
    "        'pos' : [],\n",
    "        'neg' : [],\n",
    "        'neu' : [],\n",
    "    }\n",
    "    \n",
    "    # Iterate through hashtags\n",
    "    for tag in tag_list:\n",
    "    \n",
    "        # Call function to get tweets\n",
    "        '''\n",
    "        Passing hashtag as query to Twitter API\n",
    "        '''\n",
    "        tweets = api.get_tweets(query = tag, count = 10)\n",
    "        \n",
    "        # Variables to store counts of pos, neg, and neu sentiments\n",
    "        ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
    "        ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
    "        netweets = [tweet for tweet in tweets if tweet['sentiment'] == 'neutral']\n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        # Print out breakdown of pct of tweets for each collection that are pos, neg, and neu\n",
    "        print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets)))\n",
    "        print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets)))\n",
    "        print(\"Neutral tweets percentage: {} % \\\n",
    "            \".format(100*(len(tweets) -(len( ntweets )+len( ptweets)))/len(tweets)))\n",
    "        \n",
    "        # Append count results to dict variable for later plotting\n",
    "        results_dict[\"pos\"].append(len(ptweets))\n",
    "        results_dict[\"neg\"].append(len(ntweets))\n",
    "        results_dict[\"neu\"].append(len(tweets) - len( ptweets) - len( ntweets ))\n",
    "\n",
    "        # printing first 5 positive tweets\n",
    "        #print(\"\\n\\nPositive tweets:\")\n",
    "        #for tweet in ptweets[:10]:\n",
    "            #print(tweet['text'])\n",
    "\n",
    "        # printing first 5 negative tweets\n",
    "        #print(\"\\n\\nNegative tweets:\")\n",
    "        #for tweet in ntweets[:10]:\n",
    "            #print(tweet['text'])\n",
    "\n",
    "        # printing first 5 neutral tweets\n",
    "        #print(\"\\n\\nNeutral tweets:\")\n",
    "        #for tweet in netweets[:10]:\n",
    "            #print(tweet['text'])\n",
    "    \n",
    "    # Create a dataframe from the results_dict\n",
    "    results_df = pd.DataFrame(results_dict)\n",
    "    \n",
    "    # Display the results of the df and dict\n",
    "    display(results_df)\n",
    "    display(results_dict)\n",
    "    \n",
    "    # Plot the results\n",
    "    display(results_df.hvplot(x=\"tag\", kind=\"bar\", title=\"Twitter Sentiment Analysis for Top 10 NFT Collections by Trade Volume\", width=1200, height=500))\n",
    "        \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # calling main function\n",
    "    main()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03015cb-1de7-4500-b23a-ace8c84b3574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dict = {'tag': ['#meebits',\n",
    "  '#cryptopunks',\n",
    "  '#terraforms',\n",
    "  '#mayc',\n",
    "  '#moonbirds',\n",
    "  '#azuki',\n",
    "  '#bayc',\n",
    "  '#dreadfulz',\n",
    "  '#clonex',\n",
    "  '#beanz'],\n",
    " 'pos': [3, 12, 0, 8, 14, 3, 6, 0, 24, 26],\n",
    " 'neg': [39, 35, 6, 10, 33, 47, 27, 21, 22, 23],\n",
    " 'neu': [8, 3, 0, 32, 3, 0, 17, 0, 4, 0]}\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "results_df.hvplot(x=\"tag\", kind=\"bar\", title=\"Twitter Sentiment Analysis for Top 10 NFT Collections by Trade Volume\", width=1200, height=500)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2ec66fa3d085a6e66869b1a678e052484c09c72639639e5b92cf1e8e9fcc898"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
